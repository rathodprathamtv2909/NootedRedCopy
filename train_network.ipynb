{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rathodprathamtv2909/NootedRedCopy/blob/master/train_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kohya sd-scripts | train_network\n",
        "\n",
        "This notebook is for running [sd-scripts](https://github.com/kohya-ss/sd-scripts) train_network.py by [Kohya](https://github.com/kohya-ss).\n",
        "\n",
        "このノートブックは[Kohya](https://github.com/kohya-ss)さんによる[sd-scripts](https://github.com/kohya-ss/sd-scripts)のtrain_network.py を実行するためのものです。\n",
        "\n",
        "# Wiki\n",
        "[train_network_README-ja.md](https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md)"
      ],
      "metadata": {
        "id": "zSM6HuYmkYCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXcznGdeyb2I"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi\n",
        "! nvcc -V\n",
        "! free -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tj65Tb_oyxtP"
      },
      "outputs": [],
      "source": [
        "# @markdown # Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "data_dir = \"/content/data\" # @param {type:\"string\"}\n",
        "gdrive_data_dir = \"/content/drive/MyDrive/AI/kohya/lora\" # @param {type:\"string\"}\n",
        "! ln -s {gdrive_data_dir} {data_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN7UJvSdzBFF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown # Initialize environment\n",
        "\n",
        "! git clone https://github.com/kohya-ss/sd-scripts.git\n",
        "\n",
        "import os\n",
        "\n",
        "conda_bin = \"/miniconda/bin/conda\"\n",
        "env_name = \"kohya\"\n",
        "init_conda = f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "conda activate {env_name}\n",
        "\"\"\"\n",
        "\n",
        "if not os.path.exists(conda_bin):\n",
        "    ! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /miniconda\n",
        "    ! rm Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "def run_script(s):\n",
        "    ! {s}\n",
        "\n",
        "run_script(f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "cd sd-scripts\n",
        "conda create -y -n {env_name} python=3.10 pip=22.2.2 cudatoolkit=11.3\n",
        "conda activate {env_name}\n",
        "conda install -y xformers -c xformers/label/dev\n",
        "python -m pip install -q -r requirements.txt\n",
        "python -m pip install -q tensorrt triton\n",
        "python -m pip install -q torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\"\"\")\n",
        "\n",
        "os.environ[\n",
        "    \"LD_LIBRARY_PATH\"\n",
        "] = f\"{os.environ['LD_LIBRARY_PATH']}:/usr/local/envs/{env_name}/lib\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6ooNLztf2p76"
      },
      "outputs": [],
      "source": [
        "# @markdown # Settings\n",
        "\n",
        "pretrained_model_name_or_path = \"/content/drive/MyDrive/AI/models/Stable-diffusion/wd-1-4-anime_e1.ckpt\"  # @param {type:\"string\"}\n",
        "pretrained_model_is_v2 = True  # @param {type:\"boolean\"}\n",
        "# @markdown ----\n",
        "\n",
        "pretrained_model_resolution = \"512,512\"  # @param [\"512,512\", \"768,768\"] {allow-input: true}\n",
        "input_dir = \"/content/drive/MyDrive/AI/my-dataset/train\" #@param {type:\"string\"}\n",
        "reg_dir = \"\" #@param {type:\"string\"}\n",
        "# @markdown ----\n",
        "\n",
        "model_name = \"my-model-v1\"  # @param {type:\"string\"}\n",
        "model_dir = f\"{data_dir}/models/{model_name}\"\n",
        "model_out_dir = f\"{model_dir}/result\"\n",
        "model_log_dir = f\"{model_dir}/logs\"\n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs(model_out_dir, exist_ok=True)\n",
        "os.makedirs(model_log_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O7jbV_oTvVpJ"
      },
      "outputs": [],
      "source": [
        "# @markdown # Optional | Preprocessing captions and tag information\n",
        "\n",
        "preprocess_caption = False  # @param {type:\"boolean\"}\n",
        "preprocess_tags = False  # @param {type:\"boolean\"}\n",
        "\n",
        "meta_exists = os.path.exists(\"/content/meta.json\")\n",
        "\n",
        "if preprocess_caption:\n",
        "    run_script(f\"\"\"{init_conda}\n",
        "python sd-scripts/finetune/merge_captions_to_metadata.py {input_dir} meta.json \\\n",
        "{\"--in_json=meta.json\" if meta_exists else \"\"}\n",
        "\"\"\")\n",
        "\n",
        "meta_exists = os.path.exists(\"/content/meta.json\")\n",
        "\n",
        "if preprocess_tags:\n",
        "    run_script(f\"\"\"{init_conda}\n",
        "python sd-scripts/finetune/merge_dd_tags_to_metadata.py {input_dir} meta.json \\\n",
        "{\"--in_json=meta.json\" if meta_exists else \"\"}\n",
        "\"\"\")\n",
        "\n",
        "# @markdown ----\n",
        "\n",
        "# @markdown # Optional | Advance acquisition of latents\n",
        "\n",
        "prepare_buckets_latents = False  # @param {type:\"boolean\"}\n",
        "batch_size = 4  # @param {type:\"number\"}\n",
        "mixed_precision = \"no\" # @param [\"no\", \"fp16\", \"bf16\"]\n",
        "\n",
        "run_script(f\"\"\"{init_conda}\n",
        "python sd-scripts/finetune/prepare_buckets_latents.py \\\n",
        "    {input_dir} meta.json meta-lat.json {pretrained_model_name_or_path} \\\n",
        "    --batch_size={batch_size} \\\n",
        "    --max_resolution=\"{pretrained_model_resolution}\" \\\n",
        "    --mixed_precision={mixed_precision} \\\n",
        "    {\"--v2\" if pretrained_model_is_v2 else \"\"}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q24hleNJvU-9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown # Training\n",
        "import os\n",
        "\n",
        "meta_exists = os.path.exists(\"/content/meta-lat.json\")\n",
        "\n",
        "prior_loss_weight = 1.0  # @param{type:\"number\"}\n",
        "batch_size = 1  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "max_steps = 5000  # @param {type:\"integer\"}\n",
        "mixed_precision = \"no\"  # @param [\"no\", \"fp16\", \"bf16\"]\n",
        "gradient_accumulation_steps = 1  # @param {type:\"integer\"}\n",
        "save_every_n_epochs = 5  # @param {type:\"integer\"}\n",
        "model_ext = \"safetensors\" #@param [\"diffusrs\", \"ckpt\", \"safetensors\"]\n",
        "network_weights = \"\"  # @param {type:\"string\"}\n",
        "gradient_checkpointing = False  # @param{type:\"boolean\"}\n",
        "use_8bit_adam = True  # @param{type:\"boolean\"}\n",
        "enable_bucket = True  # @param{type:\"boolean\"}\n",
        "color_aug = True  # @param{type:\"boolean\"}\n",
        "\n",
        "additional_arguments = \"\"  # @param{type:\"string\"}\n",
        "\n",
        "run_script(f\"\"\"{init_conda}\n",
        "accelerate launch --num_cpu_threads_per_process 2 sd-scripts/train_network.py \\\n",
        "    --pretrained_model_name_or_path={pretrained_model_name_or_path} \\\n",
        "    --train_data_dir={input_dir} \\\n",
        "    {\"--reg_data_dir=\" + reg_dir if reg_dir else \"\"} \\\n",
        "    --output_dir={model_log_dir} \\\n",
        "    --prior_loss_weight={prior_loss_weight} \\\n",
        "    --resolution={pretrained_model_resolution} \\\n",
        "    --train_batch_size={batch_size} \\\n",
        "    --learning_rate={learning_rate} \\\n",
        "    --max_train_steps={max_steps} \\\n",
        "    --mixed_precision={mixed_precision} \\\n",
        "    --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
        "    --save_every_n_epochs={save_every_n_epochs} \\\n",
        "    --save_model_as={model_ext} \\\n",
        "    --network_module=networks.lora \\\n",
        "    --network_train_unet_only \\\n",
        "    --xformers \\\n",
        "    {\"--use_8bit_adam\" if use_8bit_adam else \"\"} \\\n",
        "    {\"--enable_bucket\" if enable_bucket else \"\"} \\\n",
        "    {\"--color_aug\" if color_aug else \"\"} \\\n",
        "    {\"--gradient_checkpointing\" if gradient_checkpointing else \"\"} \\\n",
        "    {\"--v2\" if pretrained_model_is_v2 else \"\"} \\\n",
        "    {\"--in_json=/content/meta-lat.json\" if meta_exists else \"\"} \\\n",
        "    {\"--network_weights=\" + network_weights if network_weights else \"\"} \\\n",
        "    {additional_arguments}\n",
        "\n",
        "mv {model_log_dir}/last{\".\" + model_ext if model_ext != \"diffusers\" else \"\"} {model_out_dir}/\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wl2y8bBxBuT6"
      },
      "outputs": [],
      "source": [
        "# @markdown # Generate images\n",
        "\n",
        "prompt = \"masterpiece, best quality, high quality, 1girl\"  # @param {type:\"string\"}\n",
        "uc = \"worst quality, low quality, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry\"  # @param {type:\"string\"}\n",
        "lora_path = \"\"  # @param {type:\"string\"}\n",
        "seed = -1  # @param {type:\"integer\"}\n",
        "steps = 28  # @param {type:\"integer\"}\n",
        "sampler = \"euler_a\"  # @param ['ddim', 'pndm', 'lms', 'euler', 'euler_a', 'heun', 'dpm_2', 'dpm_2_a', 'dpmsolver', 'dpmsolver++', 'dpmsingle', 'k_lms', 'k_euler', 'k_euler_a', 'k_dpm_2', 'k_dpm_2_a']\n",
        "scale = 7.5  # @param {type:\"number\"}\n",
        "height = 512 # @param {type:\"slider\", min:64, max:1024, step:64}\n",
        "width = 512 # @param {type:\"slider\", min:64, max:1024, step:64}\n",
        "batch_size = 1  # @param {type:\"slider\", min:1, max:64, step:1}\n",
        "batch_count = 1  # @param {type:\"slider\", min:1, max:64, step:1}\n",
        "\n",
        "run_script(f\"\"\"{init_conda}\n",
        "accelerate launch --num_cpu_threads_per_process 2 sd-scripts/gen_img_diffusers.py \\\n",
        "    --ckpt={pretrained_model_name_or_path} \\\n",
        "    {\"--v2\" if pretrained_model_is_v2 else \"\"} \\\n",
        "    --outdir={data_dir}/outputs \\\n",
        "    --xformers \\\n",
        "    --network_module=networks.lora \\\n",
        "    --network_weights={lora_path} \\\n",
        "    --prompt=\"{prompt} --n {uc}\" \\\n",
        "    {\"--seed=\" + seed if seed != -1 else \"\"} \\\n",
        "    --steps={steps} \\\n",
        "    --sampler={sampler} \\\n",
        "    --scale={scale} \\\n",
        "    --H={height} \\\n",
        "    --W={width} \\\n",
        "    --batch_size={batch_size} \\\n",
        "    --n_iter={batch_count}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o1oR05RdSWLL"
      },
      "outputs": [],
      "source": [
        "# @markdown # Merge lora with checkpoint\n",
        "\n",
        "import os\n",
        "\n",
        "lora_model_path = \"\"  # @param {type:\"string\"}\n",
        "save_to = \"\"  # @param {type:\"string\"}\n",
        "ratios = 1  # @param {type:\"number\"}\n",
        "precision = \"bf16\"  # @param [\"float\", \"fp16\", \"bf16\"]\n",
        "save_precision = \"auto\"  # @param [\"auto\", \"float\", \"fp16\", \"bf16\"]\n",
        "out_checkpoint_file = save_to or model_out_dir + \"/checkpoints/merge.\" + model_ext\n",
        "\n",
        "run_script(f\"\"\"{init_conda}\n",
        "python sd-scripts/networks/merge_lora.py \\\n",
        "    --sd_model={pretrained_model_name_or_path} \\\n",
        "    --models={lora_model_path or model_out_dir + \"/last.\" + model_ext} \\\n",
        "    --save_to={out_checkpoint_file} \\\n",
        "    --ratios={ratios} \\\n",
        "    --precision={precision} \\\n",
        "    --save_precision={precision if save_precision == \"auto\" else save_precision}\n",
        "    {\"--v2\" if pretrained_model_is_v2 else \"\"}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Dewrisx2XDsv"
      },
      "outputs": [],
      "source": [
        "# @markdown # Convert ckpt (or safetensors) to diffusers\n",
        "\n",
        "import os\n",
        "\n",
        "checkpoint = \"\"  # @param {type:\"string\"}\n",
        "reference_model = \"hakurei/waifu-diffusion\"  # @param {type:\"string\"}\n",
        "save_to = \"\"  # @param {type:\"string\"}\n",
        "out_diffusers_dir = save_to or model_out_dir + \"/diffusers/last\"\n",
        "\n",
        "run_script(f\"\"\"{init_conda}\n",
        "python sd-scripts/tools/convert_diffusers20_original_sd.py \\\n",
        "    {checkpoint or out_checkpoint_file} \\\n",
        "    {out_diffusers_dir} \\\n",
        "    --reference_model={reference_model} \\\n",
        "    {\"--v2\" if pretrained_model_is_v2 else \"\"}\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}